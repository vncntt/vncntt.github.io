<!doctype html>









































<html
  class="not-ready lg:text-base"
  style="--bg: #faf8f1"
  lang="en-us"
  dir="ltr"
>
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>15 Questions - Vincent</title>

  
  <meta name="theme-color" />

  
  
  
  
  <meta name="description" content="
What do truly long-context models look like?
I want to give the model all my journals, notes, pictures, previous work, etc. so that it can make connections and tailor responses for me.
I imagine this to be In-between context stuffing and fine-tuning. Every ~day, the model takes all the conversations from that day and decides which to use to update its weights. In the future, will everyone have custom models?
Predictive processing?
What will human-AI collaboration look like in the future?
How much software will humans be writing in three years?
What are the comparative advantages of humans?
Is &ldquo;We don&rsquo;t need to find the most general, all-modality, solution. We just need to get something good enough to automate research. That&rsquo;s the goal. After that, there&rsquo;s a clear path and we&rsquo;re just on high-level steering.&rdquo; wrong?
Has someone created a gym environment that is a computer simulation? Actions are anything someone can do on a computer. After each episode, unit tests are run to determine reward. Why are we using screenshots?
How much does o1-style reasoning RL transfer to performing long-horizon tasks for computer use?
I don&rsquo;t get how we&rsquo;re passing the synthetic data wall. Yes, you can use o3 outputs to fine-tune 4o and get a really good o3-mini, but can you use oN outputs to get oN&#43;1?
Can you get two models to communicate through residual streams and not text? Or CoT in the latent space instead of writing everything out? Is this desirable? How do you get training data for this?
A quick perplexity search gets me these links.
We have text-to-text, text-to-image, text-to-video. What is the SOTA for text-to-action tokens in robots? There must be a way to leverage the understanding of the world language models have to robotics. How?
How much do traders use ML? It seems like a ripe field for it. Lots of money, data, smart people… Everything is probably private.
Why is Moravec&rsquo;s paradox true?
How is Adam still the best optimizer after 10 years? `
How do lightweight code-generation models like Cursor&rsquo;s work?
What is going on in interpretability these days?
Why are all the benchmarks in math and coding competitions? What happened to physics?
" />
  <meta name="author" content="Vincent" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="http://localhost:1313/main.min.css" />

  
  
  
  
  
  <link rel="preload" as="image" href="http://localhost:1313/theme.png" />

  
  
  
  
  <link rel="preload" as="image" href="https://www.gravatar.com/avatar/aa3d0a914a3e24c88fd02de43021311d?s=160&amp;d=identicon" />
  
  

  
  
  

  
  
  <script
    defer
    src="http://localhost:1313/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
  
  
  
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css"
  integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI"
  crossorigin="anonymous"
/>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js"
  integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t"
  crossorigin="anonymous"
></script>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js"
  integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05"
  crossorigin="anonymous"
></script>


<script>
  document.addEventListener('DOMContentLoaded', () =>
    renderMathInElement(document.body, {
      
      
      delimiters: [
        { left: '$$', right: '$$', display: true },
        { left: '$', right: '$', display: false },
      ],
      
      throwOnError: false,
    }),
  );
</script>

  
  
  

  
  <link
    rel="icon"
    href="http://localhost:1313/favicon.ico"
  />
  <link
    rel="apple-touch-icon"
    href="http://localhost:1313/apple-touch-icon.png"
  />

  
  <meta name="generator" content="Hugo 0.143.1">

  
  
  
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    <header class="mx-auto flex h-[4.5rem] max-w-[--w] px-8 lg:justify-center">
  <div class="relative z-50 ltr:mr-auto rtl:ml-auto flex items-center">
    <a class="-translate-y-[1px] text-2xl font-medium" href="http://localhost:1313/"
      >Vincent</a
    >
    <div
      class="btn-dark text-[0] ltr:ml-4 rtl:mr-4 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"
      role="button"
      aria-label="Dark"
    ></div>
  </div>

  <div
    class="btn-menu relative z-50 ltr:-mr-8 rtl:-ml-8 flex h-[4.5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
    role="button"
    aria-label="Menu"
  ></div>

  

  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = '#faf8f1'.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
  >
    
    
    <nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-10 rtl:space-x-reverse">
      
      <a
        class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
        href="/about/"
        >About</a
      >
      
      <a
        class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
        href="/notes/"
        >Notes</a
      >
      
      <a
        class="block text-center text-xl leading-[5rem] lg:text-base lg:font-normal"
        href="/now/"
        >Now</a
      >
      
    </nav>
    

    
  </div>
</header>


    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100vh-9rem)] max-w-[--w] px-8 pb-16 pt-14 dark:prose-invert"
    >
      

<article>
  <header class="mb-14">
    <h1 class="!my-0 pb-2.5">15 Questions</h1>

    
    <div class="text-xs antialiased opacity-60">
      
      <time>Feb 4, 2025</time>
      
      
      
      
    </div>
    
  </header>

  <section><ol>
<li>What do truly long-context models look like?
I want to give the model all my journals, notes, pictures, previous work, etc. so that it can make connections and tailor responses for me.
I imagine this to be In-between context stuffing and fine-tuning. Every ~day, the model takes all the conversations from that day and decides which to use to update its weights. In the future, will everyone have custom models?
Predictive processing?</li>
<li>What will human-AI collaboration look like in the future?</li>
<li>How much software will humans be writing in three years?
What are the comparative advantages of humans?</li>
<li>Is &ldquo;We don&rsquo;t need to find the most general, all-modality, solution. We just need to get something good enough to automate research. That&rsquo;s the goal. After that, there&rsquo;s a clear path and we&rsquo;re just on high-level steering.&rdquo; wrong?</li>
<li>Has someone created a gym environment that is a computer simulation? Actions are anything someone can do on a computer. After each episode, unit tests are run to determine reward. Why are we using screenshots?</li>
<li>How much does o1-style reasoning RL transfer to performing long-horizon tasks for computer use?</li>
<li>I don&rsquo;t get how we&rsquo;re passing the synthetic data wall. Yes, you can use o3 outputs to fine-tune 4o and get a really good o3-mini, but can you use oN outputs to get oN+1?</li>
<li>Can you get two models to communicate through residual streams and not text? Or CoT in the latent space instead of writing everything out? Is this desirable? How do you get training data for this?
A quick perplexity search <a href="https://transformer-circuits.pub/2023/privileged-basis/index.html">gets</a> <a href="https://arxiv.org/html/2406.03230v2">me</a> <a href="https://www.alignmentforum.org/posts/X26ksz4p3wSyycKNB/gears-level-mental-models-of-transformer-interpretability">these</a> <a href="https://www.reddit.com/r/LocalLLaMA/comments/1gxxqs9/why_should_thoughts_be_word_tokens_in_o1_style/">links</a>.</li>
<li>We have text-to-text, text-to-image, text-to-video. What is the SOTA for text-to-action tokens in robots? There must be a way to leverage the understanding of the world language models have to robotics. How?</li>
<li>How much do traders use ML? It seems like a ripe field for it. Lots of money, data, smart people… Everything is probably private.</li>
<li>Why is Moravec&rsquo;s paradox true?</li>
<li>How is Adam still the best optimizer after 10 years? `</li>
<li>How do lightweight code-generation models like Cursor&rsquo;s work?</li>
<li>What is going on in interpretability these days?</li>
<li>Why are all the benchmarks in math and coding competitions? What happened to physics?</li>
</ol>
</section>

  
  

  
  
  
  
  <nav
    class="mt-24 flex overflow-hidden rounded-xl bg-black/[3%] text-lg !leading-[1.2] *:flex *:w-1/2 *:items-center *:p-5 *:font-medium *:no-underline dark:bg-white/[8%] [&>*:hover]:bg-black/[2%] dark:[&>*:hover]:bg-white/[3%]"
  >
    
    <a class="ltr:pr-3 rtl:pl-3" href="http://localhost:1313/notes/2025-02-09-pins/"
      ><span class="ltr:mr-1.5 rtl:ml-1.5">←</span><span>Pins</span></a
    >
    
    
    <a class="ltr:ml-auto rtl:mr-auto justify-end pl-3" href="http://localhost:1313/notes/2025-01-17-ideas/"
      ><span>Ideas</span><span class="ltr:ml-1.5 rtl:mr-1.5">→</span></a
    >
    
  </nav>
  
  

  
  

  
  

  


  
</article>


    </main>

    <footer
  class="mx-auto flex h-[4.5rem] max-w-[--w] items-center px-8 text-xs uppercase tracking-wider opacity-60"
>
  <div class="mr-auto">
  
    &copy; 2025
    <a class="link" href="http://localhost:1313/">Vincent</a>
  
  </div>
  <a class="link mx-6" href="https://gohugo.io/" rel="noopener" target="_blank"
    >powered by hugo️️</a
  >️
  <a
    class="link"
    href="https://github.com/nanxiaobei/hugo-paper"
    rel="noopener"
    target="_blank"
    >hugo-paper</a
  >
</footer>

  </body>
</html>
